<!DOCTYPE html>
<html lang="en">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="">
  <meta name="author" content="">

  <title>VidSitu Dataset: Situation Recognition in Videos</title>

  <!-- Bootstrap core CSS -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@allenai/varnish@2.0.16/dist/shellac.min.css">

  <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- <link href="css/heroic-features.css" rel="stylesheet"> -->
  <!-- Custom styles for this template -->
  <!-- <link href="/open-iconic/font/css/open-iconic-bootstrap.css" rel="stylesheet"> -->
  <link rel="icon" href="https://allenai.org/favicon.ico">
  <script src="./js/style_stuff.js"></script>
  <style>
    html {
      scroll-behavior: smooth;
    }

    .icon {
      fill: 'white';
    }

    .icona {
      /* fill: white; */
      height: 25px;
      padding: 4px;
    }

    .card {
      border: 0px;
    }

    .card-text {
      font-size: small;
    }

    .jumbotron a[href],
    #paper_img a[href],
    #read_paper a[href],
    a[href].iconbox {
      color: white
    }

    #main_bg_img {
      background-image: radial-gradient(circle, rgba(8, 8, 8, 0.6), rgba(45, 45, 45, 0.9)),
        url('/assets/mosaic_vidsitu.jpg');
      /* background-image: radial-gradient(#000000, #9198e5), url('/assets/mosaic_vidsitu.jpg'); */
      width: 100%;
      height: 300px;
      background-size: cover;
      color: white;
      padding: 10px;

    }

    #paper_img {
      position: relative;
    }

    .bibtex {
      display: block;
      padding: 9.5px;
      margin: 0 0 10px;
      font-size: 13px;
      line-height: 1.42857143;
      word-break: break-all;
      word-wrap: break-word;
      color: #333;
      background-color: #f5f5f5;
      border: 1px solid #ccc;
      border-radius: 4px;
    }

    .card-img-top2 {
      width: 50%;
      transform: translate(50%, 0%);
    }

    .card-img-top-resize {
      width: 100%;
      height: 15vh;
      object-fit: cover;
    }

    .img_cont {
      position: relative;
    }

    .cropimg {
      position: relative;
      top: -60px;
      clip-path: polygon(0 7%, 100% 7%, 100% 100%, 0% 100%);
    }

    h1 {
      padding-top: 56px;
    }

    #authors .card-text {
      font-size: 16px;
    }

    .btn-primary {
      color: #fff;
      background-color: #333355;
      border-color: #333355;
    }

    .btn-primary:hover {
      color: #fff;
      background-color: #0069d9;
      border-color: #0062cc;
    }
  </style>

</head>

<body>
  <!-- Navigation -->
  <!-- <header id='myHeader'>
    <div class="banner">
      <div class="content">
        <a href="https://allenai.org">
          <img src="https://cdn.jsdelivr.net/npm/@allenai/varnish@2.0.16/dist/ai2.svg" alt="Allen Institute for AI">
        </a>
      </div>
    </div>
  </header>
  -->
  <nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top" id='main_navbar'>
    <!-- <div class="navbar-brand"><a href="index.html"><img src="/assets/VideoSituations.svg"></a></div> -->

    <div class="container">
      <a href="https://allenai.org">
        <img src="https://cdn.jsdelivr.net/npm/@allenai/varnish@2.0.16/dist/ai2.svg" alt="Allen Institute for AI">
      </a>
      <!-- <a class="navbar-brand" href="#">VidSitu</a> -->
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarResponsive"
        aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="navbarResponsive">
        <ul class="navbar-nav ml-auto">
          <li class="nav-item active">
            <a class="nav-link" href="/index.html#">VidSitu
              <!-- <span class="sr-only">(current)</span> -->
            </a>
          </li>
          <li class="nav-item">
            <!-- Add Arxiv Link -->
            <a class="nav-link" href="/index.html#paper">Paper</a>
          </li>
          <li class="nav-item">
            <!-- Authors -->
            <a class="nav-link" href="/index.html#auths">Authors</a>
          </li>
          <li class="nav-item">
            <!-- Download Instructions -->
            <a class="nav-link" href="/index.html#download">Download</a>
          </li>
          <li class="nav-item">
            <!-- Github Link -->
            <a class="nav-link" href="/index.html#code">Code</a>
          </li>
          <li class="nav-item">
            <!-- Challenge Link -->
            <a class="nav-link" href="/challenge.html" style="color: #FF9300">Challenge @ CVPR 21</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="/index.html#contact">Contact</a>
          </li>
        </ul>
      </div>
      <div class='clearer'></div>
    </div>
  </nav>

  <!-- Page Content -->
  <div class="container-fluid">
    <!-- <img src='assets/mosaic_vidsitu.jpg'> -->
    <!-- Jumbotron Header -->
    <!-- <div class="jumbotron text-center" style='background-image: url("/assets/mosaic_vidsitu.jpg");'> -->
    <div class="jumbotron text-center" id='main_bg_img'>

      <div class='container pt-5'>
        <!-- <img src='/assets/VideoSituations.svg' class='img-fluid' style='width: 200px;'> -->
        <!-- <img src='/assets/tmp_pics/VSitu.png' class='img-fluid'> -->
        <br>
        <span style="font-size: 50px;">Video Semantic Role Labeling Challenge </span><br>
        <span style='font-size: 25px;'><br>Part of the ActivityNet Challenges</span>
        <span style='font-size: 25px;'><br>CVPR 2021</span>

      </div>
      <!-- <div class='container'>
        <img src='/assets/VideoSituations.svg' class='img-fluid' style='width: 200px;'>
      </div> -->

      <!-- <h1 class=" display-3" style=' color:white'>VidSitu</h1> -->
      <!-- <a href="#download" class="btn btn-primary btn-lg iconbox">
        <img src="/open-iconic-master/svg/data-transfer-download.svg" class='icona'>Download</a>
      <a href="#paper1" class="btn btn-primary btn-lg iconbox">
        <img src='/open-iconic-master/svg/file.svg' class="icona">Paper</a>
      <a href="#bibtex" class="btn btn-primary btn-lg iconbox">
        <img src='/open-iconic-master/svg/book.svg' class='icona'>BibTex</a>
      <a href="#code" class='btn btn-primary btn-lg iconbox'>
        <img src='/open-iconic-master/svg/code.svg' class='icona'>Code</a> -->

    </div>

    <!-- Page Features -->
    <!-- <div class="row text-center"> -->
    <div class="container py-0" align="center">
      <img src="assets/vidsitu_subtasks.gif" width="80%">
    </div>

    <div class="container py-0">
      <h1>Overview</h1>
      <div class='text-center'>
        <div class="py-3" align="left">
          <p>
            Videos often depict complex real-life situations. While the vision community continues to make progress on
            building blocks like activity recognition, temporal localization, and tracking, the goal of this challenge
            is to strive for more complete video understanding than can be afforded by action labels and object
            detection only. Specifically, this challenge evaluates the ability of vision algorithms to understand
            complex <b>related events</b> in a video. Each event may be described by a <b>verb</b> corresponding to the
            most salient action in a video segment and its <b>semantic roles</b>. VidSRL involves 3 sub-tasks: (1)
            predicting a verb-sense describing the most salient action; (2) predicting the semantic roles for a given
            verb; and (3) predicting event relations given the verbs and semantic roles for two events.
          </p>
          <h4>Why not just study video captioning?</h4>
          <p>
            While producing accurate and descriptive captions for videos would be a remarkable display of algorithmic
            video understanding, VidSRL provides a more <b>complete</b> and <b>structured</b> representation of
            <b>related events</b>, and a more thorough <b>three-part evaluation</b>.
          </p>
        </div>
      </div>
    </div>

    <div class="container py-0">
      <h1>Data</h1>
      <div class='text-center'>
        <div class="py-3" align="left">
          <p>
            The challenge is based on the VidSitu dataset which consists of over 80 hours of richly annotated
            movie-clips. VidSitu has 29.2K 10-second videos annotated with events every 2 seconds. We refer to each 2
            second segment as a clip. The train, validation and test splits are desribed below. Note that the train and
            validation annotations are available for download where as the test annotations are only available through
            the online evaluation server.
          </p>
          <div align="center">
            <a href="https://github.com/TheShadow29/VidSitu/tree/main/data"
              class="btn btn-primary btn-lg iconbox">Download VidSitu Dataset</a>
          </div>
          <br>

          <table style="width:100%" class="table">
            <thead>
              <tr>
                <th>Split</th>
                <th>Description</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>Train</td>
                <td>23626 videos with each of the five 2-second clips within a video is annotated with a verb and
                  corresponding semantic roles</td>
              </tr>
              <tr>
                <td>Validation</td>
                <td>1326 videos annotated similar to the train set</td>
              </tr>
              <tr>
                <td>Test-Vb</td>
                <td>1353 videos for evaluating verb-sense prediction. Each clip is annotated with 3 verbs to account for
                  variability in selection of the salient activity</td>
              </tr>
              <tr>
                <td>Test-SRL</td>
                <td>1598 videos for evaluating semantic role prediction for a chosen verb. Each clip is annotated with 3
                  sets of semantic roles for the same verb to account for variability in referring expressions.</td>
              </tr>
              <tr>
                <td>Test-ER</td>
                <td>1317 videos for evaluating event-relation prediction. Each clip is annotated with relation to the
                  central event (the 4-6 second clip). We provide 3 annotations to handle relation ambiguity.</td>
              </tr>
            </tbody>
          </table>
        </div>
      </div>
    </div>

    <div class="container py-0">
      <h1>Submission</h1>
      <div class='text-center'>
        <div class="py-3" align="left">
          <p>
            The VidSRL evaluation has three parts, each with its own leaderboard. For the purpose of the callenge, we
            will announce winners for each leaderboard. Each leaderboard requires submitting a single .pkl file of
            predictions for the corresponding test split. Detailed submission instructions, including prediction formats
            required for evaluation, are available on the respective leaderboards. Below, <b>video</b> refers to a
            10-second video segment which consists of the 5 non-overlapping 2-second <b>clips</b> and the <b>central
              clip</b> refers to the segment spanning the 4-6 second interval within the video.
          </p>
          <table style="width:100%" class="table">
            <thead>
              <tr>
                <th>Leaderboard</th>
                <th>Input</th>
                <th>Output</th>
                <th>Test Split</th>
                <!-- <th>Leaderboard</th> -->
              </tr>
            </thead>
            <tbody>
              <tr>
                <td class="align-middle">
                  <a href="https://leaderboard.allenai.org/vidsitu-verbs/submissions/public">
                    <img src="/assets/VidSitu_logos_v2/VidSitVerbs.svg" width="40%" class="img-thumbnail">
                  </a>
                </td>
                <!-- <td class="align-middle">Verb Prediction</td> -->
                <td class="align-middle">Video</td>
                <td class="align-middle">Verb-sense per clip</td>
                <td class="align-middle">Test-Vb</td>
                <!-- <td class="align-middle"><a href="https://leaderboard.allenai.org/vidsitu-verbs/submissions/public">Link</a></td> -->
              </tr>
              <tr>
                <td class="align-middle">
                  <a href="https://leaderboard.allenai.org/vidsitu-semantic-roles/submissions/public">
                    <img src="/assets/VidSitu_logos_v2/VidSitSemantic.svg" width="40%" class="img-thumbnail">
                  </a>
                </td>
                <!-- <td>Semantic Role Prediction</td> -->
                <td class="align-middle">Video and verbs for each clip</td>
                <td class="align-middle">Semantic roles per clip</td>
                <td class="align-middle">Test-SRL</td>
                <!-- <td class="align-middle"><a href="https://leaderboard.allenai.org/vidsitu-semantic-roles/submissions/public">Link</a></td> -->
              </tr>
              <tr>
                <td class="align-middle">
                  <a href="https://leaderboard.allenai.org/vidsitu-event-relations/submissions/public">
                    <img src="/assets/VidSitu_logos_v2/VidSitEvent.svg" width="40%" class="img-thumbnail">
                  </a>
                </td>
                <!-- <td>Event-Relation Prediction</td> -->
                <td class="align-middle">Video, verbs, and semantic roles for each clip</td>
                <td class="align-middle">Relation of each clip to the central clip</td>
                <td class="align-middle">Test-ER</td>
                <!-- <td class="align-middle"><a href="https://leaderboard.allenai.org/vidsitu-event-relations/submissions/public">Link</a></td> -->
              </tr>
            </tbody>
          </table>
        </div>
      </div>
    </div>

    <div class="container py-0">
      <h1>Schedule</h1>
      <div class='text-center'>
        <div class="py-3" align="left">
          <table style="width:100%" class="table">
            <thead>
              <tr>
                <th>When</th>
                <th>What</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>April 5</td>
                <td>Evaluation servers and leaderboards online</td>
              </tr>
              <tr>
                <td>June 4</td>
                <td>Submission deadline for challenge purposes</td>
              </tr>
              <tr>
                <td>June 19-25</td>
                <td>Winners announced during the ActivityNet Workshop @ CVPR 2021</td>
              </tr>
            </tbody>
          </table>
        </div>
      </div>
    </div>


    <div class="container pt-0">
      <h1 id="contact">Contact</h1>
      <div class="text-center">
        <div class="py-3" align="left">
          <p>Please reach out to Arka Sadhu (asadhu@usc.edu) for any queries.</p>
        </div>
      </div>
    </div>



  </div>
  <!-- /.container -->

  <!-- Footer -->
  <footer>
    <div class="content">
      <div class="text-center">
        <a href="https://allenai.org">
          © The Allen Institute for Artificial Intelligence
        </a>
        &nbsp;&nbsp;|&nbsp;&nbsp;
        <a href="https://allenai.org/privacy-policy.html">
          Privacy Policy
        </a>
        &nbsp;&nbsp;|&nbsp;&nbsp;
        <a href="https://allenai.org/terms.html">
          Terms of Use
        </a>
      </div>
    </div>
  </footer>


  <!-- Bootstrap core JavaScript -->
  <script src="vendor/jquery/jquery.min.js"></script>
  <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="js/style_stuff.js"></script>

  <script>
    header_fixer()
    // correct_scroll()
    init_ds_cards('ds_cards')
    init_task_cards('task_cards')
    init_download_cards('download_cards')
    init_team_members('authors')
    init_code_cards('code_cards')
  </script>


</body>

</html>